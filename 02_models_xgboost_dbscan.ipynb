{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiUCRyFzB367"
      },
      "outputs": [],
      "source": [
        "# Mounts Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import essential Python libraries\n",
        "# pandas is used for tabular data manipulation.\n",
        "# numpy is used for numerical computations.\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bTM8HhgzEAmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/msc-dessertation-traffic/data/accidents_clean.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Original size:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "# SAMPLE for DBSCAN (to avoid RAM crash)\n",
        "df_sample = df.sample(n=130000, random_state=42)\n",
        "\n",
        "print(\"Sampled size:\", df_sample.shape)\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "XRQO_wbQEHSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "dzAwbwmgEPF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fix object columns before XGBoost ---\n",
        "\n",
        "# Convert Time (HH:MM) to minutes since midnight\n",
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H:%M\", errors=\"coerce\")\n",
        "df[\"Time\"] = df[\"Time\"].dt.hour * 60 + df[\"Time\"].dt.minute\n",
        "\n",
        "# Drop rows where Time could not be parsed\n",
        "df = df.dropna(subset=[\"Time\"])\n",
        "\n",
        "# Check data types\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "id": "K70O-mUeiAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop([\"Accident_Severity\", \"Accident_Index\", \"Date\"], axis=1)\n",
        "y = df[\"Accident_Severity\"]\n",
        "\n",
        "# Ensure ALL features are numeric\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X = X.dropna()\n",
        "\n",
        "# Align y with X after dropping rows\n",
        "y = y.loc[X.index]\n",
        "\n",
        "print(X.dtypes)\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "id": "zh6wVqUCFHM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# XGBoost labels must start at 0\n",
        "y_train_xgb = y_train - 1\n",
        "y_test_xgb  = y_test - 1\n",
        "\n"
      ],
      "metadata": {
        "id": "IWGdVlgCFK2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install xgboost\n",
        "\n"
      ],
      "metadata": {
        "id": "qrPLl_i4FPic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(y_train.unique()), sorted(y_test.unique())\n",
        "\n"
      ],
      "metadata": {
        "id": "4kVv9tBaFW52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"multi:softprob\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train_xgb)\n",
        "print(\"XGBoost training completed\")\n"
      ],
      "metadata": {
        "id": "OHKMH6IucR_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the accuarcy and confusion matrix report\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_xgb, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_xgb, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_xgb, y_pred))\n"
      ],
      "metadata": {
        "id": "9WrXZri6jN8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords = df_sample[[\"Longitude\", \"Latitude\"]].dropna().copy()\n",
        "print(\"Coords size:\", coords.shape)\n",
        "coords.head()\n"
      ],
      "metadata": {
        "id": "-m07SkCTktw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "coords_scaled = scaler.fit_transform(coords)\n",
        "print(\"Scaled shape:\", coords_scaled.shape)\n"
      ],
      "metadata": {
        "id": "keFWii3uoQvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the DBSCAN clustering algorithm to identify spatial accident hotspots.\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.25, min_samples=30)\n",
        "clusters = dbscan.fit_predict(coords_scaled)\n",
        "\n",
        "coords[\"Hotspot_Cluster\"] = clusters\n",
        "coords[\"Hotspot_Cluster\"].value_counts().head(10)\n"
      ],
      "metadata": {
        "id": "7_ninQcrokw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# 1) Use your sampled dataframe\n",
        "coords = df_sample[[\"Latitude\", \"Longitude\"]].dropna().copy()\n",
        "print(\"Coords used:\", coords.shape)\n",
        "\n",
        "# 2) Convert to radians for haversine distance\n",
        "coords_rad = np.radians(coords[[\"Latitude\", \"Longitude\"]].values)\n",
        "\n",
        "# 3) DBSCAN parameters (km-based)\n",
        "kms = 0.5  # try 0.3, 0.5, 1.0 if needed\n",
        "eps = kms / 6371.0088\n",
        "\n",
        "dbscan = DBSCAN(\n",
        "    eps=eps,\n",
        "    min_samples=20,\n",
        "    metric=\"haversine\",\n",
        "    algorithm=\"ball_tree\"\n",
        ")\n",
        "\n",
        "clusters = dbscan.fit_predict(coords_rad)\n",
        "coords[\"Hotspot_Cluster\"] = clusters\n",
        "\n",
        "print(coords[\"Hotspot_Cluster\"].value_counts().head(10))\n",
        "print(\"Clusters (excluding noise):\", coords[coords[\"Hotspot_Cluster\"] != -1][\"Hotspot_Cluster\"].nunique())\n"
      ],
      "metadata": {
        "id": "kBDAQ1AIxmVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hotspots = coords[coords[\"Hotspot_Cluster\"] != -1]\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.scatter(\n",
        "    hotspots[\"Longitude\"],\n",
        "    hotspots[\"Latitude\"],\n",
        "    c=hotspots[\"Hotspot_Cluster\"],\n",
        "    cmap=\"tab10\",\n",
        "    s=6\n",
        ")\n",
        "plt.title(\"DBSCAN Accident Hotspots (Sampled STATS19)\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Hotspot points:\", hotspots.shape[0])\n"
      ],
      "metadata": {
        "id": "6asJu8Pdxs39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords[\"Hotspot_Cluster\"].value_counts().head()\n"
      ],
      "metadata": {
        "id": "Sr51C1jkyAwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install folium\n",
        "\n",
        "import folium\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "6_4J1R-d2qaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only hotspot clusters (exclude noise -1)\n",
        "hotspots = coords[coords[\"Hotspot_Cluster\"] != -1].copy()\n",
        "\n",
        "print(\"Hotspot points:\", hotspots.shape[0])\n",
        "print(\"Clusters:\", hotspots[\"Hotspot_Cluster\"].nunique())\n",
        "\n",
        "# Keep only TOP 5 biggest clusters (to keep map fast)\n",
        "top_clusters = hotspots[\"Hotspot_Cluster\"].value_counts().head(5).index\n",
        "hotspots_top = hotspots[hotspots[\"Hotspot_Cluster\"].isin(top_clusters)].copy()\n",
        "\n",
        "print(\"Top hotspot points:\", hotspots_top.shape[0])\n",
        "print(\"Top clusters:\", hotspots_top[\"Hotspot_Cluster\"].unique())\n"
      ],
      "metadata": {
        "id": "CO4GtKKW2vy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Centre map at mean of top hotspots\n",
        "center_lat = hotspots_top[\"Latitude\"].mean()\n",
        "center_lon = hotspots_top[\"Longitude\"].mean()\n",
        "\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=6, tiles=\"cartodbpositron\")\n",
        "m\n"
      ],
      "metadata": {
        "id": "-b31EcRS21KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add points as CircleMarkers\n",
        "for _, row in hotspots_top.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "        radius=3,\n",
        "        popup=f\"Cluster: {row['Hotspot_Cluster']}\",\n",
        "        color=\"red\",\n",
        "        fill=True,\n",
        "        fill_opacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "m\n"
      ],
      "metadata": {
        "id": "NJm2j4nH27eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = folium.Map(location=[center_lat, center_lon], zoom_start=6, tiles=\"cartodbpositron\")\n",
        "\n",
        "for cl in top_clusters:\n",
        "    layer = folium.FeatureGroup(name=f\"Cluster {cl}\")\n",
        "    temp = hotspots_top[hotspots_top[\"Hotspot_Cluster\"] == cl]\n",
        "\n",
        "    for _, row in temp.iterrows():\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "            radius=3,\n",
        "            popup=f\"Cluster: {row['Hotspot_Cluster']}\",\n",
        "            fill=True,\n",
        "            fill_opacity=0.6\n",
        "        ).add_to(layer)\n",
        "\n",
        "    layer.add_to(m2)\n",
        "\n",
        "folium.LayerControl().add_to(m2)\n",
        "m2\n"
      ],
      "metadata": {
        "id": "K9XyjICU3N45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/content/drive/MyDrive/msc-dessertation-traffic/results\", exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "9USZ3oiT3fn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_path = \"/content/drive/MyDrive/msc-dessertation-traffic/results/hotspot_map.html\"\n",
        "m2.save(out_path)\n",
        "print(\"Saved:\", out_path)"
      ],
      "metadata": {
        "id": "nwl_sXGY3oSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(\n",
        "    hotspots_top[\"Longitude\"],\n",
        "    hotspots_top[\"Latitude\"],\n",
        "    c=hotspots_top[\"Hotspot_Cluster\"],\n",
        "    s=5\n",
        ")\n",
        "plt.title(\"Accident Hotspots Identified using DBSCAN (Sampled Data)\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.savefig(\"/content/drive/MyDrive/msc-dessertation-traffic/results/hotspot_map.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g9VZRgYI7xhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}